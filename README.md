# Documentaci√≥n del Proyecto eCommerce Microservices

### Santiago Jose Belalcazar - A00381777
### Kevin Vincent Loachamin Almeida - A00382106

## 1. Introducci√≥n

### 1.1 Objetivo del Taller

Este taller tiene como prop√≥sito guiar el desarrollo de una arquitectura de microservicios robusta y escalable para un sistema de comercio electr√≥nico, aplicando las mejores pr√°cticas de ingenier√≠a de software. El proyecto busca no solo implementar la soluci√≥n t√©cnica, sino tambi√©n fomentar la comprensi√≥n profunda de los principios de microservicios, DevOps, automatizaci√≥n y calidad de software. Los objetivos principales son:

- **Dise√±ar una arquitectura desacoplada y escalable**, donde cada microservicio pueda evolucionar y desplegarse de forma independiente, facilitando la innovaci√≥n y la resiliencia.
- **Automatizar el ciclo de vida del software** mediante pipelines CI/CD con Jenkins, asegurando entregas r√°pidas, seguras y repetibles.
- **Garantizar portabilidad y consistencia** usando Docker para la containerizaci√≥n de servicios, permitiendo que el entorno de desarrollo, pruebas y producci√≥n sean equivalentes.
- **Orquestar y gestionar servicios en producci√≥n** con Kubernetes, asegurando alta disponibilidad, autoescalado y despliegues controlados.
- **Implementar un enfoque integral de testing**, cubriendo desde pruebas unitarias hasta pruebas de rendimiento, para asegurar la calidad y confiabilidad del sistema.
- **Asegurar observabilidad y trazabilidad** con herramientas de monitoreo distribuido, facilitando la detecci√≥n y resoluci√≥n de problemas en entornos complejos.
- **Centralizar la gesti√≥n de configuraci√≥n** para mantener la coherencia y flexibilidad en todos los entornos.

### 1.2 Metodolog√≠a √Ågil: Scrum

El desarrollo de este proyecto se realiza siguiendo la **metodolog√≠a √°gil Scrum**, permitiendo una gesti√≥n iterativa e incremental del trabajo, con entregas frecuentes y retroalimentaci√≥n continua. El proyecto se planifica en **2 sprints**, cada uno con objetivos claros y entregables definidos, asegurando la culminaci√≥n exitosa del sistema en el tiempo estimado.

- **Sprint 1:** Enfocado en la arquitectura base, configuraci√≥n de infraestructura, despliegue inicial de microservicios y pruebas unitarias/integraci√≥n.
- **Sprint 2:** Orientado a la integraci√≥n completa, pruebas E2E, optimizaci√≥n, pruebas de rendimiento y despliegue final en producci√≥n.

Esta estructura facilita la adaptaci√≥n a cambios, la colaboraci√≥n entre los miembros del equipo y la entrega continua de valor.

---

### 1.3 Herramienta de Gesti√≥n √Ågil: Jira

Para la gesti√≥n y seguimiento de la metodolog√≠a Scrum, se utiliza **Jira** como herramienta principal. Jira permite organizar y visualizar el backlog, las historias de usuario, tareas t√©cnicas y el avance de los sprints, proporcionando transparencia y control sobre el progreso del proyecto.

- **Configuraci√≥n del proyecto en Jira:**
    ![Configuraci√≥n del proyecto en Jira](images/jira_project_setup.png)

- **Historias de usuario y backlog:**
    ![Historias de usuario en Jira](images/jira_user_stories1.png)
    ![Historias de usuario en Jira](images/jira_user_stories2.png)
    ![Historias de usuario en Jira](images/jira_user_stories3.png)
    ![Historias de usuario en Jira](images/jira_user_stories4.png)
    ![Historias de usuario en Jira](images/jira_user_stories5.png)

- **Sprints inicializados y tablero Scrum:**
  ![Sprint en Jira](images/jira_sprint_board.png)

Estos espacios permiten documentar visualmente la organizaci√≥n y el avance del proyecto, facilitando la comunicaci√≥n y la toma de decisiones dentro del equipo.

---

### 1.4 Estrategia de Branching

Para garantizar un flujo de trabajo ordenado, colaborativo y seguro, el repositorio implementa una **estrategia de branching GitHub Flow** basada en las mejores pr√°cticas de integraci√≥n y entrega continua. Esta estrategia permite aislar el desarrollo de nuevas funcionalidades, facilitar pruebas en diferentes entornos y asegurar la estabilidad del c√≥digo en producci√≥n.

#### Ramas principales del repositorio

- **master**
  - Es la rama principal y representa el entorno de **producci√≥n**.
  - Solo recibe cambios validados y probados, generalmente mediante pull requests desde `stage`.
  - Cada despliegue a producci√≥n se realiza desde esta rama.
- **stage**
  - Rama intermedia destinada al entorno de **staging**.
  - Aqu√≠ se integran y prueban los cambios antes de ser promovidos a producci√≥n.
  - Recibe merges desde `dev` y es utilizada para pruebas end-to-end, integraci√≥n y rendimiento.
- **dev**
  - Rama de **desarrollo** activo.
  - Todos los desarrolladores integran aqu√≠ sus cambios antes de pasar a `stage`.
  - Es el espacio para validaci√≥n temprana, pruebas unitarias y de integraci√≥n.

![Ramas del repositorio](images/branch.png)

#### Ramas de soporte

- **feature/\***
  - Para cada nueva funcionalidad o mejora, se crea una rama `feature/nombre-funcionalidad` a partir de `dev`.
  - Permite el desarrollo aislado de nuevas caracter√≠sticas sin afectar la estabilidad de las ramas principales.
  - Una vez completada y revisada, la rama feature se fusiona de vuelta a `dev` mediante pull request.

#### Flujo de trabajo

1. **Crear rama feature:**
   - Desde `dev`, crear una rama `feature/nueva-funcionalidad`.
2. **Desarrollar y probar localmente:**
   - Realizar commits y pruebas en la rama feature.
3. **Merge a dev:**
   - Al finalizar, abrir un pull request hacia `dev` para revisi√≥n y pruebas unitarias/integraci√≥n.
4. **Promover a stage:**
   - Una vez validados los cambios en `dev`, se realiza merge a `stage` para pruebas E2E y de rendimiento.
5. **Despliegue a producci√≥n:**
   - Tras la validaci√≥n en `stage`, los cambios se fusionan a `master` para el despliegue final.

#### Beneficios de la estrategia

- Permite desarrollo paralelo y seguro de nuevas funcionalidades.
- Facilita la integraci√≥n y pruebas en diferentes entornos antes de llegar a producci√≥n.
- Minimiza riesgos de errores en producci√≥n y mejora la trazabilidad de cambios.
- Compatible con pipelines CI/CD automatizados para cada rama.

---

### 1.5 Microservicios Seleccionados y Justificaci√≥n

La arquitectura est√° compuesta por **10 microservicios principales** y **3 servicios de infraestructura**, cada uno dise√±ado para cumplir una responsabilidad espec√≠fica dentro del ecosistema de comercio electr√≥nico:

#### Microservicios de Negocio

| Microservicio | Puerto | Justificaci√≥n |
|---------------|--------|---------------|
| **user-service** | 8700 | Gestiona toda la l√≥gica relacionada con usuarios (registro, autenticaci√≥n, perfiles). Separado para permitir escalabilidad independiente y seguridad especializada. |
| **product-service** | 8500 | Maneja el cat√°logo de productos, inventario y b√∫squedas. Crucial para el rendimiento ya que es uno de los servicios m√°s consultados. |
| **order-service** | 8300 | Procesa y gestiona pedidos. Requiere alta disponibilidad y consistencia de datos, por lo que se beneficia de estar aislado. |
| **payment-service** | 8400 | Procesa transacciones financieras. Separado por seguridad, cumplimiento PCI-DSS y para permitir integraci√≥n con m√∫ltiples gateways de pago. |
| **shipping-service** | 8600 | Gestiona env√≠os y log√≠stica. Permite integraci√≥n independiente con diferentes proveedores de transporte. |
| **favourite-service** | 8800 | Maneja listas de favoritos de usuarios. Microservicio ligero que puede escalar independientemente seg√∫n el uso. |

#### Servicios de Infraestructura

| Servicio | Puerto | Justificaci√≥n |
|----------|--------|---------------|
| **service-discovery** (Eureka) | 8761 | Registro y descubrimiento autom√°tico de servicios. Fundamental para la comunicaci√≥n din√°mica entre microservicios. |
| **cloud-config** | 9296 | Configuraci√≥n centralizada externa. Permite cambios de configuraci√≥n sin redespliegue y mantiene consistencia entre entornos. |
| **api-gateway** | - | Punto de entrada √∫nico para clientes. Proporciona routing, load balancing, autenticaci√≥n y rate limiting. |

#### Servicios de Soporte

| Servicio | Puerto | Justificaci√≥n |
|----------|--------|---------------|
| **proxy-client** | - | Cliente proxy para comunicaci√≥n entre servicios. Abstrae la comunicaci√≥n HTTP y maneja circuit breakers. |
| **zipkin** | 9411 | Trazabilidad distribuida. Esencial para debugging y monitoring de requests que atraviesan m√∫ltiples servicios. |

### 1.6 Herramientas y Tecnolog√≠as Utilizadas

#### üîß Desarrollo y Framework
- **Spring Boot**: Framework principal para el desarrollo de microservicios Java

- **Maven**: Gesti√≥n de dependencias y construcci√≥n de proyectos
- **Java 11**: Versi√≥n LTS para estabilidad y soporte a largo plazo

#### DevOps y CI/CD
- **Jenkins**: Orquestaci√≥n de pipelines de CI/CD con stages automatizados
  - Construcci√≥n y empaquetado con Maven
  - Ejecuci√≥n de pruebas automatizadas (unitarias, integraci√≥n, E2E)
  - Construcci√≥n y push de im√°genes Docker
  - Despliegue automatizado en Kubernetes
- **Git**: Control de versiones con branching strategy (dev, release, master)

####  Containerizaci√≥n y Orquestaci√≥n
- **Docker**: Containerizaci√≥n de todos los servicios para garantizar portabilidad
- **Docker Hub**: Registro de im√°genes para distribuci√≥n
- **Kubernetes**: Orquestaci√≥n de contenedores con manifests YAML
  - Deployments, Services, ConfigMaps
  - Health checks y rolling updates
  - Namespace isolation (`ecommerce`)

####  Testing y Calidad
- **JUnit**: Pruebas unitarias para l√≥gica de negocio
- **Spring Boot Test**: Pruebas de integraci√≥n con contexto de aplicaci√≥n
- **Locust**: Herramienta de testing de performance y estr√©s
  - Pruebas de carga con 5 usuarios concurrentes
  - Pruebas de estr√©s con 10 usuarios concurrentes
  - Generaci√≥n de reportes HTML con m√©tricas detalladas
- **Testcontainers**: Testing de integraci√≥n con contenedores reales



Esta arquitectura robusta permite escalabilidad horizontal, fault tolerance, y deployment independiente de cada servicio, cumpliendo con los principios fundamentales de microservicios y las mejores pr√°cticas de la industria.

## 2. Arquitectura General

### 2.1 Diagrama de Arquitectura de Microservicios

El siguiente diagrama ilustra la arquitectura l√≥gica del sistema, mostrando la interacci√≥n entre microservicios, servicios de infraestructura y componentes de soporte. Esta visi√≥n global facilita la comprensi√≥n de los flujos de datos, la resiliencia y la escalabilidad del sistema.

![Diagrama de Arquitectura](app-architecture.drawio.png)

### 2.2 Interacciones entre los Servicios

- **API Gateway:** Punto de entrada √∫nico, gestiona autenticaci√≥n, balanceo de carga y enrutamiento inteligente.
- **Service Discovery (Eureka):** Permite el registro y descubrimiento din√°mico de servicios, facilitando la escalabilidad y tolerancia a fallos.
- **Cloud Config:** Centraliza la configuraci√≥n, permitiendo cambios sin redespliegue y manteniendo la coherencia entre entornos.
- **Proxy Client:** Abstrae la comunicaci√≥n HTTP y gestiona circuit breakers, mejorando la resiliencia.
- **Zipkin:** Proporciona trazabilidad distribuida, esencial para el monitoreo y la depuraci√≥n de flujos complejos.
- **Microservicios de negocio:** Interact√∫an mediante llamadas HTTP internas, gestionadas por el API Gateway y el Service Discovery, asegurando independencia y escalabilidad.


### 2.3 Patrones de Dise√±o en la Nube Implementados

La arquitectura implementa varios **Cloud Design Patterns** que garantizan escalabilidad, resiliencia y mantenibilidad:

#### Service Discovery Pattern
Permite que los microservicios se registren y descubran din√°micamente.
- **Implementaci√≥n:** Eureka.
- **Ejemplo:**
order-service
  [`@EnableEurekaClient`](order-service/src/main/java/com/selimhorri/app/OrderServiceApplication.java#L7)
  
  ```java
  @SpringBootApplication
  @EnableEurekaClient
  public class OrderServiceApplication {
    
    public static void main(String[] args) {
      SpringApplication.run(OrderServiceApplication.class, args);
    }
  }
  ```
  user-service
  [`@EnableEurekaClient`](user-service/src/main/java/com/selimhorri/app/UserServiceApplication.java#L7)
  
  ```java
  @SpringBootApplication
  @EnableEurekaClient
  public class UserServiceApplication {

    public static void main(String[] args) {
      SpringApplication.run(UserServiceApplication.class, args);
    }
  }
  ```
  product-service
  [`@EnableEurekaClient`](product-service/src/main/java/com/selimhorri/app/ProductServiceApplication.java#L7)

  ```java
  @SpringBootApplication
  @EnableEurekaClient
  public class ProductServiceApplication {

    public static void main(String[] args) {
      SpringApplication.run(ProductServiceApplication.class, args);
    }
  }
  ```

#### API Gateway Pattern
Punto de entrada √∫nico para clientes, maneja enrutamiento y autenticaci√≥n.
- **Implementaci√≥n:** Microservicio [`api-gateway`](api-gateway/).
- **Referencia:** [k8s/api-gateway/deployment.yaml](k8s/api-gateway/deployment.yaml)

#### Centralized Configuration Pattern
Gesti√≥n centralizada de configuraci√≥n para todos los servicios.
- **Implementaci√≥n:** Spring Cloud Config.
- **Ejemplo:**
  [`@EnableConfigServer`](cloud-config/src/main/java/com/selimhorri/app/CloudConfigApplication.java#L7)
  ```java
  @SpringBootApplication
  @EnableEurekaClient
  @EnableConfigServer
  public class CloudConfigApplication {
    
    public static void main(String[] args) {
      SpringApplication.run(CloudConfigApplication.class, args);
    }
  }
  ```

#### Client-Side Load Balancing Pattern
Balanceo de carga entre instancias de servicios.
- **Implementaci√≥n:** `@LoadBalanced` en RestTemplate.
- **Ejemplo:**
  [`@LoadBalanced`](proxy-client/src/main/java/com/selimhorri/app/config/template/TemplateConfig.java#L8)
  ```java
  @Configuration
  public class TemplateConfig {
    
    @LoadBalanced
    @Bean
    public RestTemplate restTemplateBean() {
      return new RestTemplate();
    }
  }
  ```

#### Circuit Breaker / Resilience Pattern
Previene fallos en cascada y mejora la resiliencia.
- **Implementaci√≥n:** Feign Client preparado para circuit breakers.
- **Ejemplo:**
  ProductClientService
  [`@FeignClient`](proxy-client/src/main/java/com/selimhorri/app/business/product/service/ProductClientService.java#L13)
    ```java
  @FeignClient(name = "PRODUCT-SERVICE", contextId = "productClientService", path = "/product-service/api/products")
  public interface ProductClientService {
    
    @GetMapping
    ResponseEntity<ProductProductServiceCollectionDtoResponse> findAll();
    
    @GetMapping("/{productId}")
    ResponseEntity<ProductDto> findById(
        @PathVariable("productId") 
        @NotBlank(message = "Input must not be blank!") 
        @Valid final String productId);
    
    @PostMapping
    ResponseEntity<ProductDto> save(
        @RequestBody 
        @NotNull(message = "Input must not be NULL!") 
        @Valid final ProductDto productDto);
    
    [...]
    
  }
  ```

  OrderClientService
  [`@FeignClient`](proxy-client/src/main/java/com/selimhorri/app/business/order/service/OrderClientService.java#L13)

  ```java
  @FeignClient(name = "ORDER-SERVICE", contextId = "orderClientService", path = "/order-service/api/orders")
  public interface OrderClientService {
    
    @GetMapping
    public ResponseEntity<OrderOrderServiceDtoCollectionResponse> findAll();
    
    @GetMapping("/{orderId}")
    public ResponseEntity<OrderDto> findById(
        @PathVariable("orderId") 
        @NotBlank(message = "Input must not be blank!") 
        @Valid final String orderId);
    
    @PostMapping
    public ResponseEntity<OrderDto> save(
        @RequestBody 
        @NotNull(message = "Input must not be NULL!") 
        @Valid final OrderDto orderDto);
    
    [...]
    
  }
  ```

#### Proxy Pattern
Desacopla la l√≥gica de negocio de la comunicaci√≥n entre servicios.
- **Implementaci√≥n:** Microservicio [`proxy-client`](proxy-client/).
- **Ejemplo:**
  [`ProductClientService.java`](proxy-client/src/main/java/com/selimhorri/app/business/product/service/ProductClientService.java)
  [`OrderClientService.java`](proxy-client/src/main/java/com/selimhorri/app/business/order/service/OrderClientService.java)

#### Sidecar Pattern (Observability)
Agrega monitoreo y trazabilidad sin modificar el c√≥digo principal.
- **Implementaci√≥n:** Zipkin.
- **Referencia:** [`zipkin/`](zipkin/)

#### Containerization & Orchestration
Portabilidad y gesti√≥n automatizada de microservicios.
- **Implementaci√≥n:** Docker y Kubernetes.
- **Referencia:**
  [`Dockerfile` de cada microservicio](product-service/Dockerfile)
  [`k8s/`](k8s/)

#### Health Check Pattern
Monitoreo y reinicio autom√°tico de servicios no saludables.
- **Implementaci√≥n:** Health checks en manifiestos de Kubernetes.
- **Referencia:**
  [`k8s/api-gateway/deployment.yaml`](k8s/api-gateway/deployment.yaml)

  ```java
    [...]

       livenessProbe:
         httpGet:
           path: /actuator/health
           port: 8080
         initialDelaySeconds: 90
         periodSeconds: 10
         failureThreshold: 3
       readinessProbe:
         httpGet:
           path: /actuator/health
           port: 8080
         initialDelaySeconds: 60
         periodSeconds: 5
         failureThreshold: 3
       volumeMounts:
       - name: common-config-volume
         mountPath: /app/config
     volumes:
     - name: common-config-volume
       configMap:
         name: common-config
  ```

  [`k8s/order-service/deployment.yaml`](k8s/order-service/deployment.yaml)

    ```java
    [...]

        livenessProbe:
          httpGet:
            path: /order-service/actuator/health
            port: 8300
          initialDelaySeconds: 90
          periodSeconds: 10
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /order-service/actuator/health
            port: 8300
          initialDelaySeconds: 60
          periodSeconds: 5
          failureThreshold: 3
        volumeMounts:
        - name: common-config-volume
          mountPath: /app/config
      volumes:
      - name: common-config-volume
        configMap:
          name: common-config 
  ```

#### Externalized Configuration Pattern
Uso de constantes y variables externas para endpoints y configuraci√≥n.
- **Ejemplo:**
  [`AppConstant.DiscoveredDomainsApi`](shipping-service/src/main/java/com/selimhorri/app/constant/AppConstant.java#L16-L36)

  ```java
  @NoArgsConstructor(access = AccessLevel.PRIVATE)
	public abstract class DiscoveredDomainsApi {
		
		public static final String USER_SERVICE_HOST = "http://USER-SERVICE/user-service";
		public static final String USER_SERVICE_API_URL = "http://USER-SERVICE/user-service/api/users";
		
		public static final String PRODUCT_SERVICE_HOST = "http://PRODUCT-SERVICE/product-service";
		public static final String PRODUCT_SERVICE_API_URL = "http://PRODUCT-SERVICE/product-service/api/products";
		
		public static final String ORDER_SERVICE_HOST = "http://ORDER-SERVICE/order-service";
		public static final String ORDER_SERVICE_API_URL = "http://ORDER-SERVICE/order-service/api/orders";
		
		public static final String FAVOURITE_SERVICE_HOST = "http://FAVOURITE-SERVICE/favourite-service";
		public static final String FAVOURITE_SERVICE_API_URL = "http://FAVOURITE-SERVICE/favourite-service/api/favourites";
		
		public static final String PAYMENT_SERVICE_HOST = "http://PAYMENT-SERVICE/payment-service";
		public static final String PAYMENT_SERVICE_API_URL = "http://PAYMENT-SERVICE/payment-service/api/payments";
		
		public static final String SHIPPING_SERVICE_HOST = "http://SHIPPING-SERVICE/shipping-service";
		public static final String SHIPPING_SERVICE_API_URL = "http://SHIPPING-SERVICE/shipping-service/api/shippings";
		
	}
  ```

  [`AppConstant.DiscoveredDomainsApi`](product-service/src/main/java/com/selimhorri/app/constant/AppConstant.java#L16-L38)

  ```java
  	@NoArgsConstructor(access = AccessLevel.PRIVATE)
	public abstract class DiscoveredDomainsApi {
		
		public static final String USER_SERVICE_HOST = "http://USER-SERVICE/user-service";
		public static final String USER_SERVICE_API_URL = "http://USER-SERVICE/user-service/api/users";
		
		public static final String PRODUCT_SERVICE_HOST = "http://PRODUCT-SERVICE/product-service";
		public static final String PRODUCT_SERVICE_API_URL = "http://PRODUCT-SERVICE/product-service/api/products";
		
		public static final String ORDER_SERVICE_HOST = "http://ORDER-SERVICE/order-service";
		public static final String ORDER_SERVICE_API_URL = "http://ORDER-SERVICE/order-service/api/orders";
		
		public static final String FAVOURITE_SERVICE_HOST = "http://FAVOURITE-SERVICE/favourite-service";
		public static final String FAVOURITE_SERVICE_API_URL = "http://FAVOURITE-SERVICE/favourite-service/api/favourites";
		
		public static final String PAYMENT_SERVICE_HOST = "http://PAYMENT-SERVICE/payment-service";
		public static final String PAYMENT_SERVICE_API_URL = "http://PAYMENT-SERVICE/payment-service/api/payments";
		
		public static final String SHIPPING_SERVICE_HOST = "http://SHIPPING-SERVICE/shipping-service";
		public static final String SHIPPING_SERVICE_API_URL = "http://SHIPPING-SERVICE/shipping-service/api/shippings";
		
	}
  ```

  [`AppConstant.DiscoveredDomainsApi`](order-service/src/main/java/com/selimhorri/app/constant/AppConstant.java#L16-L38)

  ```java
  @NoArgsConstructor(access = AccessLevel.PRIVATE)
	public abstract class DiscoveredDomainsApi {
		
		public static final String USER_SERVICE_HOST = "http://USER-SERVICE/user-service";
		public static final String USER_SERVICE_API_URL = "http://USER-SERVICE/user-service/api/users";
		
		public static final String PRODUCT_SERVICE_HOST = "http://PRODUCT-SERVICE/product-service";
		public static final String PRODUCT_SERVICE_API_URL = "http://PRODUCT-SERVICE/product-service/api/products";
		
		public static final String ORDER_SERVICE_HOST = "http://ORDER-SERVICE/order-service";
		public static final String ORDER_SERVICE_API_URL = "http://ORDER-SERVICE/order-service/api/orders";
		
		public static final String FAVOURITE_SERVICE_HOST = "http://FAVOURITE-SERVICE/favourite-service";
		public static final String FAVOURITE_SERVICE_API_URL = "http://FAVOURITE-SERVICE/favourite-service/api/favourites";
		
		public static final String PAYMENT_SERVICE_HOST = "http://PAYMENT-SERVICE/payment-service";
		public static final String PAYMENT_SERVICE_API_URL = "http://PAYMENT-SERVICE/payment-service/api/payments";
		
		public static final String SHIPPING_SERVICE_HOST = "http://SHIPPING-SERVICE/shipping-service";
		public static final String SHIPPING_SERVICE_API_URL = "http://SHIPPING-SERVICE/shipping-service/api/shippings";
		
	}
  ```


---

Estos patrones est√°n presentes en la arquitectura y el c√≥digo fuente del proyecto, asegurando una soluci√≥n robusta, escalable y alineada con las mejores pr√°cticas de la industria.

### 2.3.1 Patrones de Dise√±o Mejorados

### Mejora Implementada: Circuit Breaker / Resilience Pattern

Para fortalecer la resiliencia y la tolerancia a fallos en la arquitectura de microservicios, se mejor√≥ la implementaci√≥n del patr√≥n **Circuit Breaker** en todos los Feign Clients del microservicio `proxy-client`. Esta mejora garantiza que, ante la ca√≠da o lentitud de un microservicio dependiente, el sistema responde de manera controlada y evita fallos en cascada.

#### ¬øEn qu√© consisti√≥ la mejora?

- **Creaci√≥n de clases fallback** para cada Feign Client, devolviendo respuestas controladas o vac√≠as cuando el servicio remoto no est√° disponible.
- **Asociaci√≥n expl√≠cita del fallback** en la anotaci√≥n `@FeignClient` de cada interfaz.
- **Cobertura total**: Se implement√≥ para los servicios de producto, orden, usuario, credenciales, direcci√≥n, favoritos, pagos, categor√≠as y order items.
- **Personalizaci√≥n de respuestas**: Cada fallback retorna datos vac√≠os, nulos o mensajes de error controlados seg√∫n la l√≥gica de negocio, permitiendo que el frontend o los servicios consumidores manejen adecuadamente la indisponibilidad temporal.

#### Ejemplo de implementaci√≥n

**1. Clase Fallback para ProductClientService:**
```java
@Component
public class ProductClientServiceFallback implements ProductClientService {

    @Override
    public ResponseEntity<ProductProductServiceCollectionDtoResponse> findAll() {
        return ResponseEntity.ok(new ProductProductServiceCollectionDtoResponse());
    }

    @Override
    public ResponseEntity<ProductDto> findById(String productId) {
        return ResponseEntity.ok(new ProductDto());
    }

    @Override
    public ResponseEntity<ProductDto> save(ProductDto productDto) {
        return ResponseEntity.ok(new ProductDto());
    }

    @Override
    public ResponseEntity<ProductDto> update(ProductDto productDto) {
        return ResponseEntity.ok(new ProductDto());
    }

    @Override
    public ResponseEntity<ProductDto> update(String productId, ProductDto productDto) {
        return ResponseEntity.ok(new ProductDto());
    }

    @Override
    public ResponseEntity<Boolean> deleteById(String productId) {
        return ResponseEntity.ok(Boolean.FALSE);
    }
    
}
```

**2. Asociaci√≥n del fallback en la interfaz Feign Client:**
```java
@FeignClient(
    name = "PRODUCT-SERVICE",
    contextId = "productClientService",
    path = "/product-service/api/products",
    fallback = ProductClientServiceFallback.class
)
public interface ProductClientService {
    // M√©todos...
}
```

#### Beneficios de la mejora

- **Mayor resiliencia:** El sistema sigue funcionando y responde de forma predecible ante fallos de servicios remotos.
- **Mejor experiencia de usuario:** Se evitan errores inesperados y se pueden mostrar mensajes claros cuando un servicio no est√° disponible.
- **Facilidad de mantenimiento:** El manejo de fallos est√° centralizado y es f√°cilmente extensible a nuevos servicios.
- **Preparaci√≥n para escenarios reales:** Permite simular y manejar ca√≠das de servicios en pruebas de carga y estr√©s, validando la robustez de la arquitectura.

#### Servicios cubiertos

- ProductClientService
- OrderClientService
- OrderItemClientService
- PaymentClientService
- FavouriteClientService
- UserClientService
- CredentialClientService
- AddressClientService
- CategoryClientService

---

Esta mejora refuerza el cumplimiento de los principios de microservicios y las mejores pr√°cticas de arquitectura en la nube, asegurando un sistema robusto, escalable y preparado para escenarios de alta disponibilidad.

### 2.3.2 Patrones de Dise√±o Extra Implementados

#### Retry Pattern

El **Retry Pattern** es un patr√≥n de resiliencia que permite reintentar autom√°ticamente operaciones fallidas, mitigando errores transitorios como fallos de red o ca√≠das temporales de servicios dependientes. Su uso es fundamental en arquitecturas distribuidas para mejorar la robustez y la experiencia del usuario, evitando fallos inmediatos ante errores recuperables.

##### ¬øC√≥mo se implement√≥?

- **Tecnolog√≠a:** Se utiliz√≥ [Resilience4j Retry](https://resilience4j.readme.io/docs/retry) integrado con Spring Cloud.
- **Cobertura:** El patr√≥n se aplic√≥ a todos los Feign Clients del microservicio `proxy-client`, permitiendo reintentos autom√°ticos en la comunicaci√≥n con servicios remotos.
- **Configuraci√≥n centralizada:** Los par√°metros de retry (n√∫mero de intentos, tiempo de espera entre reintentos, excepciones a capturar) se gestionan desde el archivo `application.yml`, facilitando su ajuste sin modificar el c√≥digo fuente.

##### Ejemplo de implementaci√≥n

**1. Configuraci√≥n en `application.yml`:**
```yaml
resilience4j:
  circuitbreaker:
    instances:
      # ...servicios...
  retry:
    instances:
      productClientService:
        max-attempts: 3
        wait-duration: 500ms
        retry-exceptions:
          - org.springframework.web.client.HttpServerErrorException
          - java.io.IOException
      categoryClientService:
        max-attempts: 3
        wait-duration: 500ms
        retry-exceptions:
          - org.springframework.web.client.HttpServerErrorException
          - java.io.IOException
      # ...otros servicios...
```

**2. Anotaci√≥n en el Feign Client:**
```java
@FeignClient(
    name = "PRODUCT-SERVICE",
    contextId = "productClientService",
    path = "/product-service/api/products",
    fallback = ProductClientServiceFallback.class
)
@Retry(name = "productClientService")
public interface ProductClientService {
    // M√©todos...
}
```

##### Beneficios de la implementaci√≥n

- **Mayor tolerancia a fallos transitorios:** El sistema reintenta autom√°ticamente antes de fallar, mejorando la disponibilidad.
- **Configuraci√≥n flexible:** Permite ajustar la pol√≠tica de reintentos por servicio seg√∫n la criticidad o el comportamiento esperado.
- **No intrusivo:** No requiere modificar la l√≥gica de negocio existente.
- **Mejor experiencia de usuario:** Reduce la probabilidad de errores visibles por problemas temporales de red o servicios.

##### Servicios cubiertos

- ProductClientService
- OrderClientService
- OrderItemClientService
- PaymentClientService
- FavouriteClientService
- UserClientService
- CredentialClientService
- AddressClientService
- CategoryClientService
- CartClientService
- VerificationTokenClientService

---

Esta implementaci√≥n refuerza la resiliencia de la arquitectura, aline√°ndose con las mejores pr√°cticas de sistemas distribuidos en la nube.

#### Rate Limiter Pattern

El **Rate Limiter Pattern** es un patr√≥n de resiliencia que protege los microservicios de sobrecargas y abusos limitando la cantidad de solicitudes permitidas en un periodo de tiempo determinado. Su implementaci√≥n es fundamental para evitar la degradaci√≥n del servicio ante picos de tr√°fico o ataques de denegaci√≥n de servicio (DoS), garantizando la disponibilidad y estabilidad del sistema.

##### ¬øC√≥mo se implement√≥?

- **Tecnolog√≠a:** Se utiliz√≥ [Resilience4j RateLimiter](https://resilience4j.readme.io/docs/ratelimiter) integrado con Spring Boot.
- **Cobertura:** El patr√≥n se aplic√≥ en los endpoints REST de los recursos de productos y categor√≠as en el microservicio `product-service`.
- **Configuraci√≥n centralizada:** Los par√°metros del rate limiter (l√≠mite de solicitudes, periodo de refresco, timeout) se gestionan desde el archivo `application.yml`, permitiendo su ajuste sin modificar el c√≥digo fuente.

##### Ejemplo de implementaci√≥n

**1. Configuraci√≥n en `application.yml`:**
```yaml
resilience4j:
  ratelimiter:
    instances:
      productApi:
        limit-for-period: 5
        limit-refresh-period: 1s
        timeout-duration: 0
```
Esto permite hasta 5 solicitudes por segundo a los endpoints protegidos bajo el nombre `productApi`.

**2. Anotaci√≥n en los recursos REST:**
```java
// ProductResource.java
@GetMapping
@RateLimiter(name = "productApi")
public ResponseEntity<DtoCollectionResponse<ProductDto>> findAll() {
    // ...
}

// CategoryResource.java
@GetMapping
@RateLimiter(name = "productApi")
public ResponseEntity<DtoCollectionResponse<CategoryDto>> findAll() {
    // ...
}
```
La anotaci√≥n `@RateLimiter(name = "productApi")` protege el endpoint, aplicando la pol√≠tica definida en la configuraci√≥n.

##### Beneficios de la implementaci√≥n

- **Protecci√≥n ante sobrecarga:** Evita que un exceso de solicitudes degrade el rendimiento o cause ca√≠das del servicio.
- **Mejor experiencia de usuario:** Garantiza tiempos de respuesta estables y predecibles bajo alta demanda.
- **Configuraci√≥n flexible:** Permite ajustar los l√≠mites de solicitudes seg√∫n la criticidad del endpoint o la capacidad del servicio.
- **F√°cil integraci√≥n:** No requiere cambios en la l√≥gica de negocio existente y puede aplicarse selectivamente a m√©todos o clases.

##### Servicios y endpoints cubiertos

- `product-service`:
  - GET `/api/products` (listado de productos)
  - GET `/api/categories` (listado de categor√≠as)

---

Esta implementaci√≥n fortalece la robustez y disponibilidad del sistema, aline√°ndose con las mejores pr√°cticas de arquitecturas distribuidas y microservicios en la


### 2.4 Ambientes Definidos

El ciclo de vida del software se gestiona a trav√©s de tres ambientes principales:

- **dev:** Espacio seguro para experimentaci√≥n y desarrollo individual.
- **stage:** Entorno de integraci√≥n y pruebas end-to-end, simula condiciones de producci√≥n.
- **master (producci√≥n):** Entorno estable y seguro, donde se ejecuta la versi√≥n aprobada del sistema.

## 3. Configuraci√≥n del Entorno

### 3.1 Jenkins (Ejecuci√≥n Local en Windows con UI)

Jenkins es el motor de automatizaci√≥n que orquesta la construcci√≥n, pruebas y despliegue del sistema. Su instalaci√≥n y configuraci√≥n en Windows es sencilla y permite gestionar pipelines visualmente desde la interfaz web.

- **Instalaci√≥n:** Descarga desde [jenkins.io/download](https://www.jenkins.io/download/), instalaci√≥n asistida y acceso v√≠a navegador.
- **Desbloqueo inicial:** Uso de la clave generada autom√°ticamente para el primer acceso.
- **Plugins recomendados:** Docker Pipeline, Git, Blue Ocean (UI avanzada).
- **Gesti√≥n de pipelines:** Creaci√≥n, monitoreo y parametrizaci√≥n de jobs desde la UI.
- **Pipeline declarativa:** El `Jenkinsfile` define el flujo CI/CD, asegurando reproducibilidad y control de versiones.
- **Despliegue automatizado:** Desde la compilaci√≥n hasta el despliegue en Kubernetes, todo el ciclo est√° automatizado y versionado.

**Buenas pr√°cticas:**
- Configurar credenciales y variables sensibles desde la UI de Jenkins.
- Asegurar permisos adecuados para la ejecuci√≥n de Docker y comandos de despliegue.

### 3.2 Docker y los Dockerfiles de los Microservicios

Docker permite encapsular cada microservicio en una imagen ligera y portable, asegurando que el entorno de ejecuci√≥n sea id√©ntico en desarrollo, pruebas y producci√≥n.

- **Dockerfile por microservicio:** Define la base, dependencias, variables de entorno y comando de arranque.
- **Im√°genes optimizadas:** Uso de im√°genes base ligeras y build eficientes.
- **Orquestaci√≥n local:** Docker Compose permite levantar el sistema completo para pruebas integradas.
- **Automatizaci√≥n en pipeline:** Jenkins construye y publica las im√°genes en cada ciclo, garantizando trazabilidad y control de versiones.

### 3.3 Kubernetes

Kubernetes es la plataforma de orquestaci√≥n que gestiona el ciclo de vida de los contenedores en producci√≥n y pruebas.

- **Manifiestos YAML:** Definen deployments, servicios, ConfigMaps y otros recursos.
- **Namespace dedicado:** Aislamiento l√≥gico para el sistema eCommerce.
- **Comandos clave:**
  - `kubectl apply -f k8s/` para desplegar todos los recursos.
  - `kubectl get pods -n ecommerce` y `kubectl get svc -n ecommerce` para monitoreo.
  - `kubectl logs <nombre-del-pod> -n ecommerce` para depuraci√≥n.
- **Despliegue automatizado:** El pipeline aplica los manifiestos tras la construcci√≥n y publicaci√≥n de im√°genes.

### 3.4 Repositorio y Estructura de Carpetas

El repositorio est√° cuidadosamente organizado para reflejar la separaci√≥n de responsabilidades y facilitar la navegaci√≥n y el mantenimiento:

```
ecommerce-microservice-backend-app/
‚îÇ
‚îú‚îÄ‚îÄ api-gateway/           # Microservicio API Gateway (con su Dockerfile)
‚îú‚îÄ‚îÄ cloud-config/          # Servicio de configuraci√≥n centralizada (con su Dockerfile)
‚îú‚îÄ‚îÄ favourite-service/     # Microservicio de favoritos (con su Dockerfile)
‚îú‚îÄ‚îÄ order-service/         # Microservicio de pedidos (con su Dockerfile)
‚îú‚îÄ‚îÄ payment-service/       # Microservicio de pagos (con su Dockerfile)
‚îú‚îÄ‚îÄ product-service/       # Microservicio de productos (con su Dockerfile)
‚îú‚îÄ‚îÄ proxy-client/          # Cliente proxy para comunicaci√≥n entre servicios (con su Dockerfile)
‚îú‚îÄ‚îÄ service-discovery/     # Servicio Eureka para descubrimiento (con su Dockerfile)
‚îú‚îÄ‚îÄ shipping-service/      # Microservicio de env√≠os (con su Dockerfile)
‚îú‚îÄ‚îÄ user-service/          # Microservicio de usuarios (con su Dockerfile)
‚îú‚îÄ‚îÄ zipkin/                # Servicio de trazabilidad distribuida (con su Dockerfile)
‚îÇ
‚îú‚îÄ‚îÄ k8s/                   # Manifiestos de Kubernetes
‚îú‚îÄ‚îÄ locust/                # Pruebas de carga y rendimiento con Locust
‚îú‚îÄ‚îÄ e2e-tests/             # Pruebas de E2E
‚îú‚îÄ‚îÄ Jenkinsfile            # Pipeline de CI/CD
‚îú‚îÄ‚îÄ compose.yml            # Orquestaci√≥n local con Docker Compose
‚îú‚îÄ‚îÄ DOCUMENTATION.md       # Documentaci√≥n del proyecto
‚îú‚îÄ‚îÄ README.md              # Instrucciones r√°pidas
‚îî‚îÄ‚îÄ ...otros archivos
```

Esta estructura promueve la modularidad, la escalabilidad y la facilidad de mantenimiento, permitiendo que cada equipo o desarrollador trabaje de forma independiente en su microservicio, sin interferir con el resto del sistema.

---

## 4. Pipelines de Integraci√≥n y Entrega Continua

La automatizaci√≥n del ciclo de vida del software es clave para la agilidad y la calidad. En este proyecto, una pipeline declarativa en Jenkins gestiona de forma inteligente los flujos de integraci√≥n y despliegue para las ramas principales (`dev`, `stage`, `master`). Esto asegura que cada entorno reciba el nivel de validaci√≥n y control adecuado, minimizando riesgos y acelerando la entrega de valor. Mientras que otro pipeline declarado en Jenkins se encarga de gestionar toda la configuracion y montaje de la infraestructura del proyecto

![Pipelines Generales](images/branch3.png)

## Pipeline Principal
gestiona de forma inteligente los flujos de integraci√≥n y despliegue para las ramas principales (`dev`, `stage`, `master`), incluyendo herramientas de monitoreo, reportes y demas montajes

![Historias de usuario en Jira](images/branch1.png)

### 4.1 Pipeline para entorno de desarrollo (`dev`)

El entorno de desarrollo est√° orientado a la experimentaci√≥n y validaci√≥n r√°pida de cambios. Cada push o pull request a la rama `dev` dispara la pipeline, que ejecuta:

1. Compilaci√≥n y an√°lisis est√°tico del c√≥digo para detectar errores tempranos.
2. Pruebas unitarias y de integraci√≥n para validar la l√≥gica y la interacci√≥n interna.
3. Construcci√≥n de im√°genes Docker etiquetadas como `dev`.
4. Publicaci√≥n de im√°genes en el registro.
5. Despliegue autom√°tico en el entorno de desarrollo de Kubernetes.

Esto permite a los desarrolladores recibir feedback inmediato y trabajar en un entorno lo m√°s parecido posible a producci√≥n.


### 4.2 Pipeline para entorno de staging (`stage`)

El entorno de staging simula condiciones de producci√≥n y es el espacio para validaciones exhaustivas antes del despliegue final. Cada push a la rama `stage` ejecuta:

1. Compilaci√≥n y pruebas (unitarias, integraci√≥n y, opcionalmente, end-to-end).
2. Construcci√≥n y push de im√°genes Docker etiquetadas como `stage`.
3. Despliegue en el entorno de staging de Kubernetes.
4. Ejecuci√≥n de pruebas automatizadas post-despliegue (carga, estres, E2E, validaci√≥n de endpoints).

Esto asegura que solo versiones estables y validadas lleguen a producci√≥n.

### 4.3 Pipeline de despliegue (`master` / Producci√≥n)

El entorno de producci√≥n es el m√°s cr√≠tico y requiere validaciones adicionales. Cada push o merge a la rama `master` ejecuta:

1. Compilaci√≥n y pruebas exhaustivas.
2. Construcci√≥n y push de im√°genes Docker etiquetadas como `prod`.
3. Despliegue en el entorno de producci√≥n de Kubernetes.
4. Generaci√≥n y publicaci√≥n autom√°tica de release notes.
5. Notificaci√≥n de despliegue exitoso.

Esto garantiza trazabilidad, control y calidad en cada entrega al usuario final.

## Pipeline de infraestructura

![Pipeline de infra](images/branch2.png)
### 4.3 Descripci√≥n de la Infraestructura del Proyecto

La infraestructura del proyecto est√° definida y gestionada en la carpeta `Infra`, la cual centraliza todos los recursos y configuraciones necesarias para el despliegue automatizado y la operaci√≥n estable del ecosistema de microservicios. Esta carpeta contiene tanto la pipeline de infraestructura como los manifiestos terraform y scripts para levantar los servicios fundamentales que soportan la arquitectura.

#### Beneficios de la Infraestructura Centralizada

- **Automatizaci√≥n completa:** Todo el ciclo de provisi√≥n y despliegue de infraestructura es reproducible y versionado.
- **Escalabilidad:** Permite modificar o escalar servicios de soporte sin afectar los microservicios de negocio.
- **Mantenibilidad:** Facilita la actualizaci√≥n y el monitoreo de los servicios core desde un √∫nico punto.
- **Seguridad y consistencia:** La gesti√≥n centralizada de configuraci√≥n y secretos asegura coherencia y control de acceso.


### 4.4 Resumen del manejo de ramas y pipeline

La pipeline √∫nica, combinada con la directiva `when { branch 'nombre' }`, permite adaptar el flujo a cada entorno, asegurando que cada rama reciba el tratamiento adecuado y que los despliegues sean seguros, trazables y eficientes.

---
#### **Resultados de SonarQube**

El an√°lisis autom√°tico de calidad de c√≥digo se realiza con SonarQube en cada pipeline. Todos los microservicios del proyecto son evaluados bajo los criterios de seguridad, mantenibilidad y fiabilidad definidos en el Quality Gate.

- **Resultado global:**  
  Todos los microservicios han superado el Quality Gate, mostrando el indicador "Passed".
- **Indicadores clave:**  
  - **Seguridad:** Sin vulnerabilidades detectadas.
  - **Fiabilidad:** Sin bugs cr√≠ticos ni bloqueantes.
  - **Mantenibilidad:** C√≥digo limpio, sin deuda t√©cnica significativa.

Esto garantiza que el c√≥digo fuente cumple con los est√°ndares de calidad requeridos antes de ser promovido a los entornos superiores.

![Dashboard SonarQube](images/sonar.png)

**Implementaci√≥n de SonarQube en la pipeline (Jenkinsfile):**
```groovy
stage('Run SonarQube Analysis') {
    when { branch 'master' }
    tools {
        jdk 'JDK 17'
    }
    environment {
        JAVA_HOME = tool 'JDK 17'
        PATH = "${JAVA_HOME}/bin:${env.PATH}"
        scannerHome = tool 'lil-sonar-tool'
    }
    steps {
        script {
            def javaServices = [
                'api-gateway',
                'cloud-config',
                'favourite-service',
                'order-service',
                'payment-service',
                'product-service',
                'proxy-client',
                'service-discovery',
                'shipping-service',
                'user-service',
                'e2e-tests'
            ]

            withSonarQubeEnv(credentialsId: 'sonarqube_password', installationName: 'lil sonar installation') {
                javaServices.each { service ->
                    dir(service) {
                        bat "${scannerHome}/bin/sonar-scanner " +
                        "-Dsonar.projectKey=${service} " +
                        "-Dsonar.projectName=${service} " +
                        '-Dsonar.sources=src ' +
                        '-Dsonar.java.binaries=target/classes'
                    }
                }

                dir('locust') {
                    bat "${scannerHome}/bin/sonar-scanner " +
                    '-Dsonar.projectKey=locust ' +
                    '-Dsonar.projectName=locust ' +
                    '-Dsonar.sources=test'
                }
            }
        }
    }
}

```

---

## 5. Dise√±o y Ejecuci√≥n de Pruebas

La calidad del software es un pilar fundamental en sistemas distribuidos. Este proyecto implementa una estrategia de testing integral, cubriendo desde la l√≥gica interna de cada microservicio hasta la experiencia real del usuario y el rendimiento bajo carga. Cada tipo de prueba aporta una capa de confianza y permite detectar errores en diferentes etapas del ciclo de vida.

### 5.1 Pruebas Unitarias

Las pruebas unitarias validan la l√≥gica de negocio de cada componente de forma aislada, usando JUnit y Mockito. Permiten detectar errores en etapas tempranas y facilitan el refactorizado seguro. Cada microservicio cuenta con pruebas enfocadas en sus m√©todos cr√≠ticos, asegurando que la funcionalidad b√°sica sea confiable y mantenible.

Cada microservicio cuenta con su propio conjunto de pruebas unitarias, enfocadas en los m√©todos m√°s cr√≠ticos de su l√≥gica interna. Por ejemplo, en `user-service` se prueban m√©todos como `findById`, `save` y `update`, asegurando que el servicio gestione correctamente los datos de usuario. En `product-service` se valida la obtenci√≥n y manipulaci√≥n de productos.

| Microservicio      | Clase de prueba                       | Ejemplo de m√©todo probado                |
|--------------------|---------------------------------------|------------------------------------------|
| user-service       | UserServiceImplTest                   | testFindById_ReturnsUserDto, testSave_ReturnsSavedUserDto |
| product-service    | ProductServiceImplTest | testFindById_ReturnsProductDto, testSave_ReturnsSavedProductDto, testFindById_ThrowsException_WhenNotFound |

**Ejemplo real de prueba unitaria (user-service):**
Esta prueba verifica que el m√©todo `testFindById_ReturnsUserDto` del servicio de usuarios retorna correctamente un usuario existente. Se simula el repositorio con Mockito para devolver un usuario de prueba y se comprueba que los datos retornados coinciden con los esperados.
```java
@Test
void testFindById_ReturnsUserDto() {
    Credential credential = Credential.builder().credentialId(1).username("testuser").password("pass").isEnabled(true).isAccountNonExpired(true).isAccountNonLocked(true).isCredentialsNonExpired(true).build();
    User user = User.builder().userId(1).firstName("John").lastName("Doe").email("john@doe.com").credential(credential).build();

    credential.setUser(user);

    when(userRepository.findById(1)).thenReturn(Optional.of(user));

    UserDto result = userService.findById(1);

    assertNotNull(result);
    assertEquals("John", result.getFirstName());
    assertEquals("testuser", result.getCredentialDto().getUsername());
}
```

**Ejemplo real de prueba unitaria (product-service):**
Aqu√≠ se valida que el m√©todo `testFindById_ReturnsProductDto` del servicio de productos retorna correctamente un DTO de producto cuando existe en el repositorio simulado. Se comprueban los campos clave del producto.
```java
@Test
void testFindById_ReturnsProductDto() {
    Category category = Category.builder().categoryId(1).categoryTitle("Test Category").build();
    Product product = Product.builder().productId(1).productTitle("Test Product").category(category).build();
    when(productRepository.findById(1)).thenReturn(Optional.of(product));

    ProductDto result = productService.findById(1);

    assertNotNull(result);
    assertEquals(1, result.getProductId());
    assertEquals("Test Product", result.getProductTitle());
    assertNotNull(result.getCategoryDto());
    assertEquals("Test Category", result.getCategoryDto().getCategoryTitle());
}
```

---

### 5.2 Pruebas de Integraci√≥n

Las pruebas de integraci√≥n validan la interacci√≥n entre componentes dentro de un microservicio, asegurando que los endpoints REST y la integraci√≥n entre capas funcionen correctamente. Usan bases embebidas o contenedores para simular el entorno real y detectar problemas de configuraci√≥n o comunicaci√≥n.

Por ejemplo, tanto en el `user-service` como en `product-service` se prueba la creaci√≥n de un usuario y producto respectivamente a trav√©s del endpoint REST, verificando que la respuesta sea la esperada y que los datos se almacenen correctamente.

**Ejemplo real de prueba de integraci√≥n (user-service):**
Esta prueba simula una petici√≥n HTTP POST para crear un usuario, usando `TestRestTemplate`. Se verifica que la respuesta sea exitosa y que los datos retornados coincidan con los enviados.
```java
@Test
void testSaveAndFindUser() {
    Credential credential = Credential.builder().username("integrationUser").password("pass").isEnabled(true).isAccountNonExpired(true).isAccountNonLocked(true).isCredentialsNonExpired(true).build();
    User user = User.builder().firstName("Jane").lastName("Smith").email("jane@smith.com").credential(credential).build();

    credential.setUser(user);

    user = userRepository.save(user);

    Optional<User> found = userRepository.findById(user.getUserId());
    assertTrue(found.isPresent());
    assertEquals("Jane", found.get().getFirstName());
    assertEquals("integrationUser", found.get().getCredential().getUsername());
}
```

**Ejemplo real de prueba de integraci√≥n (product-service):**
Esta prueba simula una petici√≥n HTTP POST para crear un producto, usando `TestRestTemplate`. Se verifica que la respuesta sea exitosa y que los datos retornados coincidan con los enviados.
```java
@Test
void testSaveAndFindProduct() {
    Category category = Category.builder().categoryTitle("Electronics").build();
    category = categoryRepository.save(category);

    Product product = Product.builder().productTitle("Laptop").category(category).build();
    product = productRepository.save(product);

    Optional<Product> found = productRepository.findById(product.getProductId());
    assertTrue(found.isPresent());
    assertEquals("Laptop", found.get().getProductTitle());
    assertEquals("Electronics", found.get().getCategory().getCategoryTitle());
}
```

---

### 5.3 Pruebas E2E (End-to-End)

Las pruebas E2E simulan flujos completos de usuario a trav√©s de varios microservicios, validando la integraci√≥n real del sistema en condiciones similares a producci√≥n. Son clave para asegurar que los procesos cr√≠ticos del negocio funcionen de extremo a extremo y que la experiencia del usuario sea consistente.

**Ejemplo real de prueba E2E (user-service):**
Esta prueba simula el registro completo de un usuario, enviando un payload complejo que incluye credenciales y direcci√≥n. Se valida que el endpoint acepte la petici√≥n y retorne un c√≥digo de √©xito.
```java
@Test
void shouldSaveUser() {
    Map<String, Object> credentialPayload = Map.of(
            "username", "e2euser",
            "password", "e2epassword",
            "roleBasedAuthority", "ROLE_USER",
            "isEnabled", true,
            "isAccountNonExpired", true,
            "isAccountNonLocked", true,
            "isCredentialsNonExpired", true
    );

    Map<String, Object> addressPayload = Map.of(
            "fullAddress", "123 E2E Test St",
            "postalCode", "12345",
            "city", "E2E City"
    );

    Map<String, Object> userPayload = Map.of(
            "firstName", "E2E",
            "lastName", "User",
            "imageUrl", "http://placeholder:200",
            "email", "e2euser@example.com",
            "phone", "1234567890",
            "addressDtos", List.of(addressPayload),
            "credential", credentialPayload
    );

    ResponseEntity<String> response = restFacade.post(
            userServiceUrl + "/user-service/api/users",
            userPayload,
            String.class
    );

    System.out.println("Response: " + response.getBody());
    System.out.println("Status Code: " + response.getStatusCode());
    assertTrue(response.getStatusCode().is2xxSuccessful(), "Unexpected status code: " + response.getStatusCode());
}
```

**Ejemplo real de prueba E2E (order-service):**
Esta prueba comprueba que el endpoint de ordenes retorna correctamente la lista de ordenes del usuario autenticado, validando la integraci√≥n entre autenticaci√≥n, l√≥gica de negocio y persistencia.
```java
@Test
void shouldGetAllOrders() {
    ResponseEntity<String> response = restFacade.get(orderServiceUrl + "/order-service/api/orders", String.class);
    System.out.println("Response: " + response.getBody());
    System.out.println("Status Code: " + response.getStatusCode());
    assertTrue(response.getStatusCode().is2xxSuccessful(), "Unexpected status code: " + response.getStatusCode());
}
```

**Ejemplo real de prueba E2E (favourite-service):**
Esta prueba comprueba que el endpoint de favoritos retorna correctamente la lista de favoritos del usuario autenticado, validando la integraci√≥n entre autenticaci√≥n, l√≥gica de negocio y persistencia.
```java
@Test
void shouldGetAllFavourites() {
    ResponseEntity<String> response = restFacade.get(favouriteServiceUrl + "/favourite-service/api/favourites",String.class);
    System.out.println("Response: " + response.getBody());
    System.out.println("Status Code: " + response.getStatusCode());
    assertTrue(response.getStatusCode().is2xxSuccessful(), "Unexpected status code: " + response.getStatusCode());
}
```

---

### 5.4 Pruebas de Rendimiento con Locust

Las pruebas de rendimiento, realizadas con Locust, permiten simular usuarios concurrentes y medir la capacidad, estabilidad y tiempos de respuesta del sistema bajo carga. Son esenciales para identificar cuellos de botella y validar la escalabilidad antes de exponer el sistema a usuarios reales.

Los scripts de Locust, ubicados en la carpeta `locust/`, definen escenarios de uso t√≠picos, como navegaci√≥n de productos y creaci√≥n de √≥rdenes. Se pueden ajustar el n√∫mero de usuarios concurrentes y el tiempo de espera entre acciones para simular diferentes condiciones de carga.

**Ejemplo real de script Locust (locust/locustfile.py):**
Este script define dos tareas principales: consultar la lista de productos y crear una orden. Cada usuario virtual ejecuta estas tareas de forma aleatoria, permitiendo medir el rendimiento de los endpoints m√°s cr√≠ticos del sistema.
```python
from locust import HttpUser, task, between

class EcommerceUser(HttpUser):
    wait_time = between(1, 5)

    @task
    def view_products(self):
        self.client.get("/products")

    @task
    def create_order(self):
        self.client.post("/orders", json={"productId": 1, "quantity": 1})
```

Al ejecutar estas pruebas, Locust genera reportes detallados con m√©tricas como tiempos de respuesta, throughput y tasa de errores, facilitando la toma de decisiones para optimizaci√≥n y dimensionamiento del sistema.

## 6. Proceso Paso a Paso del Taller: Implementaci√≥n de Microservicios con CI/CD

Esta secci√≥n describe de manera detallada y secuencial c√≥mo se implement√≥ el proyecto de microservicios de eCommerce, incluyendo la configuraci√≥n de Docker, el despliegue en Kubernetes con Minikube, la configuraci√≥n de Jenkins para CI/CD, y las pruebas de rendimiento con Locust. Cada proceso se documenta tal como fue ejecutado durante el desarrollo real del proyecto.

### 6.1 Configuraci√≥n del Entorno de Desarrollo Local

El desarrollo comenz√≥ con la configuraci√≥n de un entorno local que permitiera ejecutar todos los microservicios de manera integrada. Para esto se utiliz√≥ Docker Compose como herramienta principal de orquestaci√≥n local. Los archivos `core.yml` y `compose.yml` fueron dise√±ados para levantar todos los servicios necesarios del ecosistema de microservicios de forma coordinada.

La configuraci√≥n inicial requiri√≥ la creaci√≥n de un archivo Core que definiera los microservicios de infraestructura y soporte: service-discovery (Eureka Server), cloud-config (Configuration Server) y un Docker Compose que definiera cada uno de los 8 microservicios del proyecto: api-gateway, product-service, user-service, order-service, payment-service, shipping-service, favourite-service y proxy-client. Cada servicio fue configurado con sus respectivos puertos, variables de entorno y dependencias espec√≠ficas.

![alt text](images/image_core_yml.png)
![alt text](images/image_compose_yml.png)

La estructura del core.yml y compose.yml incluyen la definici√≥n de redes internas que permiten la comunicaci√≥n entre servicios, vol√∫menes persistentes para datos que requieren permanencia, y la configuraci√≥n de healthchecks para garantizar que los servicios dependientes no inicien hasta que sus dependencias est√©n completamente operativas.

### 6.2 Creaci√≥n de Dockerfiles para cada Microservicio

Cada microservicio requiri√≥ la creaci√≥n de un Dockerfile espec√≠fico que definiera su entorno de ejecuci√≥n. Durante el desarrollo se estableci√≥ un patr√≥n est√°ndar para todos los servicios Java Spring Boot, utilizando OpenJDK 11 como imagen base debido a la compatibilidad.

 El Dockerfile implementado utiliza un enfoque multi-stage que optimiza el tama√±o final de la imagen, separando la fase de construcci√≥n de la fase de ejecuci√≥n.

![alt text](images/image_dockerfile.png)



La configuraci√≥n de cada Dockerfile consider√≥ aspectos espec√≠ficos como los puertos de exposici√≥n √∫nicos para cada servicio, las variables de entorno necesarias para la conexi√≥n con otros servicios.

### 6.3 Configuraci√≥n de Docker Hub

Para almacenar y distribuir las im√°genes Docker de los microservicios, se configur√≥ Docker Hub como registro central de contenedores. Este proceso requiri√≥ la creaci√≥n de una cuenta en Docker Hub y la configuraci√≥n del repositorio para almacenar todas las im√°genes del proyecto.

Se cre√≥ la cuenta con el usuario `sanjodb` que se utiliz√≥ consistentemente a lo largo del proyecto para mantener todas las im√°genes organizadas bajo un mismo namespace. Esta configuraci√≥n facilit√≥ la gesti√≥n centralizada de versiones y el acceso controlado a las im√°genes desde diferentes entornos.

El proceso incluy√≥ la configuraci√≥n de repositorios p√∫blicos para cada uno de los 11 microservicios del proyecto. Cada servicio tiene su propio repositorio en Docker Hub siguiendo la convenci√≥n de nombres: `sanjodb/service-name`, donde service-name corresponde a cada microservicio (api-gateway, user-service, product-service, etc.).

![alt text](images/image_dockerhub_general.png)

Para automatizar el proceso de subida de im√°genes, se configuraron las credenciales de Docker Hub que posteriormente ser√≠an utilizadas por Jenkins durante el pipeline de CI/CD. Esto permite que el pipeline construya las im√°genes localmente y las suba autom√°ticamente al registro de Docker Hub con tags espec√≠ficos seg√∫n la rama y versi√≥n del c√≥digo.

La estrategia de tagging implementada utiliza diferentes etiquetas seg√∫n el entorno:
- **Tag `dev`**: Para im√°genes construidas desde la rama de desarrollo
- **Tag `stage`**: Para im√°genes del entorno de staging
- **Tag `prod`**: Para im√°genes de producci√≥n desde la rama master

![alt text](images/image_dockerhub_especifico.png)

Esta configuraci√≥n de Docker Hub es fundamental para el pipeline de CI/CD, ya que act√∫a como el puente entre la construcci√≥n de im√°genes y el despliegue en Kubernetes, permitiendo que los diferentes entornos accedan a las versiones correctas de cada microservicio.

### 6.4 Instalaci√≥n y Configuraci√≥n de Minikube

Para el entorno de Kubernetes local se procedi√≥ con la instalaci√≥n de Minikube, que permite ejecutar un cl√∫ster de Kubernetes en una m√°quina local para desarrollo y pruebas. El proceso comenz√≥ con la descarga e instalaci√≥n de Minikube desde el sitio oficial, seguido de la configuraci√≥n del driver de virtualizaci√≥n adecuado para el sistema operativo utilizado.

Una vez instalado Minikube, se procedi√≥ con la inicializaci√≥n del cl√∫ster local mediante el comando `minikube start driver=docker`. La configuraci√≥n inicial incluy√≥ la habilitaci√≥n de addons necesarios como el ingress controller y el dashboard de Kubernetes.

![alt text](images/image_minikube_docker.png)

La verificaci√≥n de la instalaci√≥n se realiz√≥ mediante comandos como `kubectl cluster-info` y `minikube dashboard` para confirmar que el cl√∫ster estaba operativo y accesible. Posteriormente se configur√≥ el contexto de kubectl para apuntar al cl√∫ster de Minikube, permitiendo la ejecuci√≥n de comandos de Kubernetes desde la terminal local.

![alt text](images/image_kubernetes.png)

### 6.5 Configuraci√≥n de Manifiestos de Kubernetes

La implementaci√≥n en Kubernetes requiri√≥ la creaci√≥n de manifiestos YAML que definieran c√≥mo cada microservicio ser√≠a desplegado en el cl√∫ster. El proceso comenz√≥ con la creaci√≥n de la estructura de carpetas `k8s/` que contendr√≠a todos los archivos de configuraci√≥n necesarios para el despliegue.

Se inici√≥ con la creaci√≥n del namespace `ecommerce` para aislar todos los recursos del proyecto en un espacio de nombres espec√≠fico. 

```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: ecommerce
```

![alt text](images/image_k8s.png)

Para cada microservicio se crearon tres tipos de manifiestos: Deployment (que define c√≥mo se ejecuta el servicio), Service (que expone el servicio internamente en el cl√∫ster), y opcionalmente Ingress (para servicios que requieren acceso externo como el Api-Gateway). Los Deployments fueron configurados con estrategias de rolling update, health checks, y resource limits apropiados para cada servicio.

El proceso incluy√≥ la configuraci√≥n espec√≠fica de cada servicio con sus respectivas variables de entorno, como las URLs de connection para la base de datos, los endpoints de service discovery (Eureka), y las configuraciones espec√≠ficas de cada microservicio. Los Services fueron configurados con ClusterIP para comunicaci√≥n interna y LoadBalancer para servicios que requieren acceso externo como el API Gateway.

![alt text](images/image_deployment.png)

![alt text](images/image_service.png)

### 6.6 Configuraci√≥n de Jenkins para CI/CD

La implementaci√≥n del pipeline de CI/CD requiri√≥ la instalaci√≥n y configuraci√≥n de Jenkins como servidor de integraci√≥n continua. El proceso comenz√≥ con la instalaci√≥n de Jenkins en el entorno local, seguido de la configuraci√≥n de plugins necesarios para Docker, Kubernetes, y Git.

![alt text](images/image_panel_deafult.png)

Una vez instalado Jenkins, se procedi√≥ con la configuraci√≥n de credenciales para acceder a Docker Hub donde se almacenar√≠an las im√°genes de los microservicios. Estas credenciales fueron configuradas con el usuario `sanjodb` que se utiliz√≥ consistentemente a lo largo del proyecto para el almacenamiento de todas las im√°genes Docker. Siendo estas credenciales necesarias para que Jenkins pueda subir las im√°genes construidas al repositorio de Docker Hub.

![alt text](images/image_credentials.png)

La configuraci√≥n incluy√≥ la instalaci√≥n de plugins espec√≠ficos como Docker Pipeline, Kubernetes CLI, y Pipeline Stage View para mejorar la funcionalidad del pipeline. Tambi√©n se configur√≥ la integraci√≥n con Git para permitir que Jenkins detecte cambios en el repositorio y ejecute el pipeline correspondiente.

![alt text](images/image_plugins.png)

Se estableci√≥ un pipeline multibranch que permite manejar diferentes ramas del repositorio de forma independiente, cada una con su propio ciclo de despliegue. Esta configuraci√≥n es particularmente √∫til durante el desarrollo cuando se trabaja con features branches que requieren despliegues separados para pruebas.

![alt text](images/image_multibranch.png)

### 6.7 Desarrollo del Jenkinsfile y Stages del Pipeline

El coraz√≥n del pipeline de CI/CD es el Jenkinsfile que define todas las etapas del proceso de construcci√≥n, pruebas y despliegue. El archivo desarrollado contiene 438 l√≠neas de c√≥digo que implementa un pipeline sofisticado con l√≥gica condicional basada en ramas y m√∫ltiples tipos de pruebas.

![alt text](images/image_jenkinsfile.png)

El Jenkinsfile implementa una estrategia de ramificaci√≥n que utiliza bloques `when {}` para definir qu√© stages se ejecutan en cada rama espec√≠fica. Esta configuraci√≥n permite diferentes flujos de trabajo seg√∫n el entorno de destino:

#### 6.7.1 Configuraci√≥n de Ramas y Profiles

El stage **Init** define la configuraci√≥n espec√≠fica para cada rama del repositorio. Utiliza un mapeo que asocia cada rama con un perfil de Spring y un tag de imagen espec√≠fico:

- **master**: Utiliza perfil `prod` con tag `prod` para despliegues en producci√≥n
- **stage**: Utiliza perfil `stage` con tag `stage` para el entorno de staging 
- **dev**: Utiliza perfil `dev` con tag `dev` para desarrollo local
- **feature/**: Ramas de caracter√≠sticas que heredan la configuraci√≥n de dev

```groovy
def profileConfig = [
    master : ['prod', '-prod'],
    stage  : ['stage', '-stage']
]
def config = profileConfig[env.BRANCH_NAME] ?: ['dev', '-dev']
```

#### 6.7.2 Stages Principales del Pipeline

**Stage: Build & Package**
```groovy
when { anyOf { branch 'master'; branch 'stage'; branch 'dev'; } }
```
Este stage ejecuta `mvn clean package -DskipTests` y se activa en las ramas principales. Construye todos los microservicios del proyecto sin ejecutar pruebas para optimizar tiempo de construcci√≥n.

![alt text](images/image_build&package.png)

**Stage: Build & Push Docker Images** 
```groovy
when { anyOf { branch 'stage'; branch 'master' } }
```
Exclusivo para ramas `stage` y `master`, este stage construye y sube las im√°genes Docker a DockerHub con el usuario `sanjodb`. Cada uno de los 11 microservicios es procesado individualmente con tags espec√≠ficos seg√∫n la rama.

![alt text](images/image_buildandpushdocker.png)

**Stage: Unit Tests**
```groovy
when {
    anyOf {
        branch 'dev'; branch 'stage';
        expression { env.BRANCH_NAME.startsWith('feature/') }
    }
}
```
Ejecuta pruebas unitarias en `user-service` y `product-service`. Se activa en ramas de desarrollo, staging y ramas de feature. Los resultados se publican usando el plugin JUnit de Jenkins.

![alt text](images/image_unit_test.png)

**Stage: Integration Tests**
```groovy
when {
    anyOf {
        branch 'dev'; branch 'stage';
        expression { env.BRANCH_NAME.startsWith('feature/') }
    }
}
```
Ejecuta pruebas de integraci√≥n usando `mvn verify` en `user-service` y `product-service`. Valida la interacci√≥n entre componentes y la integraci√≥n con bases de datos embebidas.

![alt text](images/image_integration.png)

**Stage: E2E Tests**
```groovy
when { anyOf { branch 'stage'; } }
```
Exclusivo para la rama `stage`, ejecuta las pruebas end-to-end que validan flujos completos de usuario a trav√©s de m√∫ltiples microservicios. Utiliza el m√≥dulo `e2e-tests` del proyecto.

![alt text](images/image_e2e.png)

### 6.8 Ejecuci√≥n Espec√≠fica por Rama

#### 6.8.1 Rama Development (dev)
En la rama `dev` se ejecutan los siguientes stages:
- Init (configuraci√≥n dev)
- Ensure Namespace 
- Checkout
- Verify Tools
- Build & Package
- Unit Tests
- Integration Tests

![alt text](images/image_general_dev.png)
![alt text](images/image_pipeline_dev.png)

#### 6.8.2 Rama Staging (stage)  
La rama `stage` ejecuta el pipeline m√°s completo incluyendo:
- Todos los stages de `dev`
- Build & Push Docker Images
- E2E Tests
- Levantar contenedores para pruebas
- Run Load Tests with Locust
- Run Stress Tests with Locust  
- Detener y eliminar contenedores

![alt text](images/image_stage_general.png)
![alt text](images/image_pipeline_stage.png) 
![alt text](images/image_pipeline_stage_2.png) 

#### 6.8.3 Rama Master (master)
La rama `master` se enfoca en despliegue a producci√≥n:
- Init (configuraci√≥n prod) 
- Build & Package
- Build & Push Docker Images  
- Deploy Common Config
- Deploy Core Services
- Deploy Microservices
- Generate and Archive Release Notes 

![alt text](images/image_master_general.png)
![alt text](images/image_rama_master.png)

### 6.8 Implementaci√≥n Completa de Pruebas

![alt text](images/image_test.png)

#### 6.8.1 Pruebas Unitarias
Las pruebas unitarias se ejecutan en las ramas `dev`, `stage` y `feature/*` usando Maven. El pipeline ejecuta `mvn test` espec√≠ficamente en los servicios que contienen pruebas unitarias implementadas: `user-service`, `product-service` y `payment-service`. Los resultados se publican autom√°ticamente en Jenkins a trav√©s del plugin JUnit.

![alt text](images/image_test_unitarios.png)
![alt text](images/image_unitarios_pipelineJ.png)

#### 6.8.2 Pruebas de Integraci√≥n  
Las pruebas de integraci√≥n utilizan `mvn verify` y se ejecutan en `user-service` y `product-service`. Estas pruebas validan la correcta integraci√≥n entre las capas de la aplicaci√≥n, incluyendo controladores REST, servicios y repositorios con bases de datos embebidas.

![alt text](images/image_test_integracion.png)
![alt text](images/image_test_integracionJ.png)

#### 6.8.3 Pruebas End-to-End (E2E)
Las pruebas E2E se ejecutan exclusivamente en la rama `stage` usando el m√≥dulo `e2e-tests`. Estas pruebas validan flujos completos de usuario que atraviesan m√∫ltiples microservicios, asegurando que la integraci√≥n entre servicios funcione correctamente en un entorno similar a producci√≥n.

![alt text](images/image_test_e2e.png)
![alt text](images/image_test_e2eJ.png)

#### 6.8.4 Pruebas de Rendimiento con Locust

**Stage: Levantar contenedores para pruebas**
Antes de ejecutar las pruebas de Locust, el pipeline levanta un entorno de pruebas completo usando Docker. Este stage crea una red `ecommerce-test` y despliega secuencialmente:
- Zipkin (trazabilidad)
- Service Discovery (Eureka)  
- Cloud Config (configuraci√≥n centralizada)
- Todos los microservicios de negocio

![alt text](images/image_test_containers.png)

Cada servicio incluye health checks para asegurar que est√© completamente operativo antes de continuar.

**Stage: Run Load Tests with Locust**
Ejecuta pruebas de carga normal con 10 usuarios concurrentes (`-u 5 -r 2 -t 1m`) en tres servicios cr√≠ticos:
- order-service (puerto 8300)
- payment-service (puerto 8400)  
- favourite-service (puerto 8800)

![alt text](images/image_load_test.png)

Cada prueba genera un reporte HTML espec√≠fico que se almacena en `locust-reports/`.

**Stage: Run Stress Tests with Locust**  
Ejecuta pruebas de estr√©s con 50 usuarios concurrentes (`-u 10 -r 5 -t 1m`) en los mismos servicios. Estas pruebas eval√∫an el comportamiento del sistema bajo alta carga y permiten identificar puntos de quiebre y cuellos de botella.

![alt text](images/image_stress_test.png)

### 6.9 Resultados 

#### 6.9.1 Resultados de Pruebas de Rendimiento

**Pruebas de Load Testing**
Los resultados de las pruebas de carga con Locust muestran el comportamiento del sistema bajo condiciones normales de uso. Los reportes HTML generados incluyen m√©tricas detalladas de:
- Tiempo de respuesta promedio y percentiles
- Throughput (requests por segundo)
- Tasa de errores
- Distribuci√≥n de tiempos de respuesta

**Favourite Service**

En las pruebas de carga, el favourite-service mostr√≥ un rendimiento muy aceptable. El tiempo de respuesta promedio fue de 520.36 ms, con un percentil 95 del tiempo de respuesta en 110 ms, lo que indica que el 95% de las peticiones fueron atendidas en menos de ese tiempo. La tasa de solicitudes por segundo (RPS) se mantuvo entre 2.0 y 2.5, sin registrar errores. Esto demuestra que el servicio se comporta de manera estable y eficiente bajo condiciones normales de uso.

![alt text](images/image_favourite_load.png)
![alt text](images/total_requests_per_second_favourite_load.png)

**Order Service**

Este servicio present√≥ el mejor rendimiento en las pruebas de carga. Con un tiempo de respuesta promedio de apenas 21.37 ms y un percentil 95 de 12 ms, el order-service maneja las peticiones con gran rapidez. Su RPS fue alrededor de 2.5, sin errores. Estas m√©tricas reflejan una alta eficiencia y bajo consumo de recursos, posicion√°ndolo como el servicio m√°s optimizado de los tres en este escenario.

![alt text](images/image_order_load.png)
![alt text](images/total_requests_per_second_order_load.png)

**Payment Service**

El payment-service mostr√≥ tiempos de respuesta notablemente m√°s altos comparado con los otros microservicios. El promedio fue de 330.83 ms, con un percentil 95 de 370 ms. Aunque la RPS fue alrededor de 2.5 y no se registraron errores, estos valores indican un rendimiento m√°s limitado, posiblemente por operaciones complejas o mayor uso de recursos. Si bien es funcional bajo carga normal, no es tan eficiente como los otros.

![alt text](images/image_payment_load.png)
![alt text](images/total_requests_per_second_payment_load.png)

**Pruebas de Stress Testing**  

Las pruebas de estr√©s revelan el comportamiento del sistema bajo alta carga, identificando:
- L√≠mites de capacidad de cada microservicio
- Degradaci√≥n del rendimiento bajo presi√≥n
- Puntos de falla del sistema
- Comportamiento de recovery despu√©s de picos de carga

**Favourite Service**

Bajo condiciones de alta carga, el favourite-service mantuvo un rendimiento sobresaliente. Logr√≥ una tasa de 5 solicitudes por segundo, con un tiempo de respuesta promedio de 64.9 ms y percentil 95 de 76 ms, sin errores reportados. Esto demuestra que el servicio escala de forma excelente, siendo robusto y confiable incluso en escenarios exigentes.

![alt text](images/image_favourite_stress.png)
![alt text](images/total_requests_per_second_favourite_stress.png)

**Order Service**

El order-service tambi√©n mostr√≥ una capacidad de escalabilidad excepcional en las pruebas de estr√©s. Alcanz√≥ una tasa de 5.5 RPS con un tiempo de respuesta promedio baj√≠simo de 9.31 ms y percentil 95 de 7 ms. Estos valores confirman que el servicio es extremadamente r√°pido y eficiente incluso con un alto volumen de peticiones simult√°neas, ideal para entornos de alta demanda.

![alt text](images/image_order_stress.png)
![alt text](images/total_requests_per_second_order_stress.png)

**Payment Service**

En contraste, el payment-service evidenci√≥ limitaciones importantes bajo estr√©s. Aunque alcanz√≥ 5.0 RPS, su tiempo de respuesta promedio se dispar√≥ a 646.35 ms, con un percentil 95 de 5200 ms y un pico m√°ximo de 1779 ms, sin errores. Aunque funcional, su rendimiento cae considerablemente bajo carga alta, lo que lo convierte en el principal candidato para optimizaci√≥n o escalamiento.

![alt text](images/image_payment_stress.png)
![alt text](images/total_requests_per_second_payment_stress.png)

#### 6.9.2 Despliegue Exitoso en Kubernetes

**Deploy Core Services**
En la rama `master`, el pipeline despliega los servicios fundamentales en el siguiente orden:
1. **Zipkin**: Sistema de trazabilidad distribuida
2. **Service Discovery**: Servidor Eureka para registro de servicios
3. **Cloud Config**: Servidor de configuraci√≥n centralizada

Cada despliegue incluye `kubectl rollout status` con timeout de 300 y 500 segundos para verificar que el servicio est√© completamente operativo.

![alt text](images/image_deploy_core.png)


**Deploy Microservices**
Posteriormente se despliegan los microservicios de negocio:
- product-service
- user-service
- order-service
- payment-service
- api-gateway

Cada microservicio se despliega con la imagen correspondiente del tag de la rama, configuraci√≥n de variables de entorno espec√≠ficas, y verificaci√≥n de rollout exitoso.

![alt text](images/image_deploy_microservices.png)

![alt text](images/image_kubernetes_pods.png)

El proceso concluye con la generaci√≥n autom√°tica de release notes usando `convco changelog` y el archivado de artefactos en Jenkins, proporcionando trazabilidad completa del despliegue y documentaci√≥n autom√°tica de cambios para cada release en producci√≥n.

![alt text](images/image_release_notes.png)

![alt text](images/image_changelog_gen.png)

![alt text](images/image_release_notes_vista.png)

## 7. Costos de Infraestructura en la Nube

Antes de abordar el an√°lisis de costos, es importante destacar el uso de **Google Cloud Platform (GCP)** como proveedor principal de infraestructura para este proyecto. GCP ofrece una plataforma robusta y escalable que permite desplegar, gestionar y monitorear microservicios de manera eficiente. Durante el desarrollo, se aprovecharon servicios como Google Kubernetes Engine (GKE), Cloud Storage y herramientas de monitoreo integradas, lo que facilit√≥ la automatizaci√≥n, la observabilidad y la gesti√≥n centralizada de recursos.

La interfaz de GCP proporciona visibilidad en tiempo real sobre el consumo de recursos, la facturaci√≥n y el estado de los servicios desplegados, permitiendo un control detallado del presupuesto y la optimizaci√≥n de la infraestructura.

![Panel de control GCP](images/cloud.png)

La gesti√≥n eficiente de los costos es fundamental en cualquier arquitectura basada en la nube. Durante el desarrollo y pruebas del proyecto, se utiliz√≥ la capa gratuita de Google Cloud Platform (GCP), lo que permiti√≥ experimentar con recursos reales sin incurrir en gastos significativos.

A continuaci√≥n se muestra un ejemplo del panel de control de GCP, donde se visualiza el consumo de cr√©ditos gratuitos y el presupuesto restante:

![Panel de costos GCP](images/costos.png)

- **Cr√©ditos usados:** $50,456 de $1,235,798 cr√©ditos disponibles en la prueba gratuita.
- **Fecha de vencimiento:** 13 de septiembre de 2025.
- **Control de presupuesto:** Se configuraron alertas para evitar sobrecostos y asegurar el uso responsable de los recursos.
- **Recomendaciones:** GCP sugiere productos como m√°quinas virtuales, bases de datos y herramientas de an√°lisis, facilitando la gesti√≥n y escalabilidad de la infraestructura.

Esta visibilidad permite tomar decisiones informadas sobre el dimensionamiento y optimizaci√≥n de los recursos, asegurando la sostenibilidad del proyecto tanto en desarrollo como en producci√≥n.

---

## 8. Monitoreo, Observabilidad y Logging Centralizado

### 8.1 Prometheus: Recolecci√≥n de M√©tricas y Gesti√≥n de Alertas

Prometheus es el sistema principal para la recolecci√≥n de m√©tricas de todos los microservicios y del cl√∫ster de Kubernetes. Permite consultar el estado de los servicios, recursos y definir reglas de alerta para situaciones cr√≠ticas.

- **Recolecci√≥n de m√©tricas t√©cnicas y de negocio**
- **Alertas autom√°ticas ante fallos o uso excesivo de recursos**
- **Integraci√≥n con Grafana para dashboards visuales**

![Prometheus UI](images/prome1.png)

#### Reglas de Alertas en Prometheus

Prometheus incluye reglas para detectar ca√≠das de pods, errores en la recarga de configuraci√≥n y problemas en el cl√∫ster.

![Prometheus Alertas](images/prome2.png)

#### Prometheus Pods
![Prometheus Alertas](images/prometheus-pods.png)

---

### 8.2 Grafana: Visualizaci√≥n de Dashboards

Grafana consume las m√©tricas de Prometheus y permite crear dashboards personalizados para monitorear la salud de los servicios y la infraestructura.

- **Dashboards de uso de CPU, memoria y estado de pods**
- **Visualizaci√≥n de m√©tricas t√©cnicas y de negocio**
- **Alertas visuales y notificaciones**

![Grafana Overview](images/grafana1.png)
![Grafana Overview 2](images/grafana2.png)
![Grafana Cluster](images/grafana3.png)
![Grafana Nodes/Pods](images/grafana4.png)
![Grafana Pods Detalle](images/grafana5.png)

---

### 8.3 ELK Stack: Centralizaci√≥n de Logs

El stack ELK (Elasticsearch, Logstash, Kibana, Filebeat) centraliza y visualiza los logs de todos los microservicios y componentes del cl√∫ster.

- **Elasticsearch:** Almacena y permite b√∫squedas r√°pidas sobre los logs.
- **Logstash:** Procesa y transforma los logs antes de almacenarlos.
- **Kibana:** Visualiza los logs y facilita el an√°lisis y monitoreo.
- **Filebeat:** Recolecta logs de los pods y los env√≠a a Logstash/Elasticsearch.

![ELK Stack](images/ELK.png)

#### Acceso y Uso

- **Kibana:** Acceso web para consultar y visualizar logs.
- **Elasticsearch:** Acceso para b√∫squedas avanzadas.
- **Logstash y Filebeat:** Funcionan en segundo plano recolectando y procesando logs.

---

### 8.4 Estado de los Pods en Kubernetes

El monitoreo de pods es esencial para asegurar la disponibilidad y el correcto funcionamiento de los microservicios.

- **Visualizaci√≥n del estado de los pods en el cl√∫ster**
- **Detecci√≥n de pods ca√≠dos o en estado no saludable**
- **Escalado y reinicio autom√°tico seg√∫n m√©tricas**

![Pods Kubernetes](images/pods.png)

---

### 8.5 Alertas y Notificaciones

El sistema de monitoreo est√° configurado para enviar alertas autom√°ticas por correo electr√≥nico ante eventos cr√≠ticos, como la ca√≠da de un servicio o el uso excesivo de recursos.

![Alertas](images/notificacion.png)

---

## 9. Seguridad y Pruebas de Vulnerabilidades

### 9.1 Escaneo de Vulnerabilidades en Contenedores con Trivy

El pipeline ejecuta un escaneo autom√°tico con **Trivy** sobre cada imagen Docker antes de desplegar en entornos de staging o producci√≥n.

- **Detecci√≥n de vulnerabilidades HIGH y CRITICAL**
- **Reporte HTML integrado en Jenkins**
- **Bloqueo autom√°tico del pipeline ante hallazgos cr√≠ticos**

Para asegurar la seguridad de las im√°genes Docker, el pipeline ejecuta un escaneo autom√°tico con **Trivy** sobre cada microservicio. Este proceso identifica vulnerabilidades de severidad **HIGH** y **CRITICAL** antes de desplegar en entornos de staging o producci√≥n.

- **Automatizaci√≥n:**  
  El stage de Trivy se ejecuta en la rama `stage`, generando reportes HTML individuales para cada imagen Docker.
- **Reporte visual:**  
  Los resultados detallan el nivel de severidad, la versi√≥n afectada y enlaces a los reportes oficiales de cada vulnerabilidad (CVE).
- **Acci√≥n ante hallazgos:**  
  Si se detectan vulnerabilidades cr√≠ticas, la pipeline puede detenerse autom√°ticamente para evitar despliegues inseguros.

**Fragmento de pipeline:**
```groovy
stage('Trivy Vulnerability Scan & Report') {
    when { branch 'stage' }
    environment {
        TRIVY_PATH = 'C:/ProgramData/chocolatey/bin'
    }
    steps {
        script {
            env.PATH = "${TRIVY_PATH};${env.PATH}"
            def services = [ ... ]
            bat """
            if not exist trivy-reports (
                mkdir trivy-reports
            )
            """
            services.each { service ->
                def reportPath = "trivy-reports\\${service}.html"
                echo "üîç Escaneando imagen ${IMAGE_TAG} con Trivy para ${service}..."
                bat """
                trivy image --format template ^
                    --template "@C:/ProgramData/chocolatey/lib/trivy/tools/contrib/html.tpl" ^
                    --severity HIGH,CRITICAL ^
                    -o ${reportPath} ^
                    ${DOCKERHUB_USER}/${service}:${IMAGE_TAG}
                """
            }
            publishHTML(target: [
                allowMissing: true,
                alwaysLinkToLastBuild: true,
                keepAll: true,
                reportDir: 'trivy-reports',
                reportFiles: '*.html',
                reportName: 'Trivy Scan Report'
            ])
        }
    }
}
```

**Ejemplo de reporte Trivy:**

![Reporte Trivy](images/trivi1.png)

- **Severity:** Nivel de criticidad (CRITICAL/HIGH)
- **Installed Version / Fixed Version:** Versi√≥n instalada y versi√≥n corregida
- **Links:** Acceso directo a los reportes CVE

Esta integraci√≥n asegura que solo im√°genes seguras y auditadas sean promovidas a los entornos superiores, reforzando la seguridad del ecosistema de microservicios.

---

### 9.2 Pruebas de Seguridad Automatizadas (OWASP ZAP)

Se integr√≥ OWASP ZAP para pruebas de seguridad din√°mica sobre los endpoints HTTP expuestos por los microservicios.

- **Detecci√≥n de vulnerabilidades en tiempo real**
- **Reporte HTML integrado en Jenkins**

![Reporte ZAP](images/zap.png)

**Fragmento del Jenkinsfile:**
```groovy
stage('OWASP ZAP Scan') {
    when { branch 'stage' }
    steps {
        script {
            echo '==> Iniciando escaneos con OWASP ZAP'

            def targets = [
                [name: 'order-service', url: 'http://order-service-container:8300/order-service'],
                [name: 'payment-service', url: 'http://payment-service-container:8400/payment-service'],
                [name: 'product-service', url: 'http://product-service-container:8500/product-service'],
                [name: 'shipping-service', url: 'http://shipping-service-container:8600/shipping-service'],
                [name: 'user-service', url: 'http://user-service-container:8700/user-service'],
                [name: 'favourite-service', url: 'http://favourite-service-container:8800/favourite-service']
            ]

            bat 'if not exist zap-reports mkdir zap-reports'

            targets.each { service ->
                def reportFile = "report-${service.name}.html"
                echo "==> Escaneando ${service.name} (${service.url})"
                bat """
                    docker run --rm ^
                    --network ecommerce-test ^
                    -v "%WORKSPACE%/zap-reports:/zap/wrk/zap-reports" ^
                    zaproxy/zap-stable ^
                    zap-full-scan.py ^
                    -t ${service.url} ^
                    -r zap-reports/${reportFile} ^
                    -I
                """
            }
            bat 'dir zap-reports'
        }
    }
}

stage('Publicar Reportes de Seguridad') {
    when { branch 'stage' }
    steps {
        echo '==> Publicando reportes HTML en interfaz Jenkins'
        publishHTML([
            allowMissing: false,
            alwaysLinkToLastBuild: true,
            keepAll: true,
            reportDir: 'zap-reports',
            reportFiles: 'report-*.html',
            reportName: 'ZAP Security Reports',
            reportTitles: 'OWASP ZAP Full Scan Results'
        ])
    }
}
```

---

## 10. M√©tricas T√©cnicas y de Negocio

Adem√°s de las m√©tricas t√©cnicas (CPU, memoria, disponibilidad), se recolectan m√©tricas de negocio como:

- Pedidos por minuto
- Tasa de registro de usuarios
- Valor promedio del pedido (AOV)

Estas m√©tricas se exponen a trav√©s de endpoints personalizados y se visualizan en Grafana.

![M√©tricas T√©cnicas](images/metricas.png)
![M√©tricas T√©cnicas 2](images/metricas2.png)

---

## 11. Aprobaciones para Despliegue en Producci√≥n

La seguridad y el control en los despliegues a producci√≥n son fundamentales en cualquier proceso de DevOps profesional. Por ello, la pipeline principal de CI/CD implementa un **stage de aprobaci√≥n manual** antes de ejecutar cualquier despliegue en el entorno productivo (`master`). Este mecanismo garantiza que solo versiones revisadas y autorizadas lleguen a los usuarios finales, permitiendo una validaci√≥n adicional por parte del equipo responsable.

### 11.1 Stage de Approval en la Pipeline

En el `Jenkinsfile`, el stage `Waiting approval for deployment` se activa exclusivamente en la rama `master`. Este stage realiza dos acciones clave:

1. **Notificaci√≥n por correo electr√≥nico:**  
   Se env√≠a autom√°ticamente un email a los responsables del proyecto (`ingesoft.proyecto@gmail.com`) informando que el build est√° listo para ser desplegado en producci√≥n y requiere revisi√≥n y aprobaci√≥n manual.

2. **Input manual en Jenkins:**  
   El pipeline se detiene y solicita una aprobaci√≥n expl√≠cita desde la interfaz de Jenkins. Solo tras la confirmaci√≥n manual, el despliegue contin√∫a hacia el cl√∫ster de Kubernetes en producci√≥n.

**Fragmento real del Jenkinsfile:**
```groovy
stage('Waiting approval for deployment') {
    when { branch 'master' }
    steps {
        script {
            emailext(
                to: 'ingesoft.proyecto@gmail.com',
                subject: "Action Required: Approval Needed for Deploy of Build #${env.BUILD_NUMBER}",
                body: """\
                The build #${env.BUILD_NUMBER} for branch *${env.BRANCH_NAME}* has completed and is pending approval for deployment.
                Please review the changes and approve or abort
                You can access the build details here:
                ${env.BUILD_URL}
                """
            )
            input message: 'Approve deployment to production (kubernetes) ?', ok: 'Deploy'
        }
    }
}
```

### 11.2 Flujo de Aprobaci√≥n

- **Finalizaci√≥n de pruebas y build:** El pipeline ejecuta todas las pruebas y construye las im√°genes Docker.
- **Notificaci√≥n autom√°tica:** Se env√≠a un correo a los responsables con el enlace al build y detalles del despliegue pendiente.
- **Revisi√≥n y validaci√≥n:** Un responsable revisa los resultados, logs y reportes generados.
- **Aprobaci√≥n manual:** Desde la UI de Jenkins, se debe hacer clic en "Deploy" para continuar.
- **Despliegue en producci√≥n:** Solo tras la aprobaci√≥n, el pipeline ejecuta los stages de despliegue en Kubernetes.

### 11.3 Beneficios del Proceso de Approval

- **Prevenci√≥n de errores:** Evita despliegues accidentales o autom√°ticos sin revisi√≥n humana.
- **Trazabilidad:** Queda registro de qui√©n y cu√°ndo se aprob√≥ cada despliegue.
- **Cumplimiento de pol√≠ticas:** Facilita auditor√≠as y cumplimiento de normativas internas o externas.
- **Colaboraci√≥n:** Permite que varios miembros del equipo participen en la validaci√≥n final.

---

Este mecanismo de aprobaci√≥n manual refuerza la seguridad, la calidad y la gobernanza del proceso de entrega continua, aline√°ndose con las mejores pr√°cticas de DevOps y despliegue

## 12 Informe de Cobertura y Calidad de Pruebas

La cobertura de pruebas es un indicador clave de la calidad del software, ya que mide el porcentaje de c√≥digo ejecutado durante la ejecuci√≥n de los tests. Para este proyecto, se utiliz√≥ **JaCoCo** como herramienta de an√°lisis de cobertura, generando reportes detallados para cada microservicio principal.

A continuaci√≥n se presenta un resumen de los resultados obtenidos, acompa√±ado de capturas reales de los reportes generados tras la ejecuci√≥n de las pruebas unitarias e integraci√≥n en el pipeline de Jenkins.

### 12.1 Cobertura en user-service

![Reporte de cobertura user-service](images/reporte-coverage2.png)

- **Cobertura total de instrucciones:** 12%
- **Cobertura de ramas:** 0%
- **Clases cubiertas:** 43
- **M√©todos cubiertos:** 395 de 470
- **L√≠neas cubiertas:** 384 de 470

**Observaciones:**
- La cobertura se concentra principalmente en los paquetes de dominio y DTOs.
- Los m√©todos cr√≠ticos de la l√≥gica de negocio y los controladores REST cuentan con pruebas, pero existen √°reas de oportunidad para ampliar la cobertura en clases auxiliares y excepciones.
- Se recomienda incrementar la cobertura en los paquetes de servicios y helpers para fortalecer la robustez del microservicio.

### 12.2 Cobertura en product-service

![Reporte de cobertura product-service](images/reporte-coverage.png)

- **Cobertura total de instrucciones:** 18%
- **Cobertura de ramas:** 0%
- **Clases cubiertas:** 26
- **M√©todos cubiertos:** 218 de 276
- **L√≠neas cubiertas:** 172 de 240

**Observaciones:**
- La cobertura es mayor en los paquetes de dominio y DTOs, reflejando un buen nivel de pruebas sobre la l√≥gica de datos.
- Los servicios y controladores principales est√°n cubiertos, pero se identifican √°reas sin pruebas en helpers y excepciones.
- Se recomienda ampliar la cobertura en los controladores y servicios para alcanzar un mayor porcentaje y reducir riesgos de regresi√≥n.

### 12.3 An√°lisis General
- **Cobertura global:** Aunque los microservicios cuentan con pruebas en los componentes m√°s cr√≠ticos, el porcentaje global es bajo respecto a los est√°ndares recomendados para entornos productivos.
- **√Åreas de mejora:** Se identifican oportunidades para incrementar la cobertura en clases utilitarias, excepciones y l√≥gica de negocio secundaria.

**Conclusi√≥n:**  
El an√°lisis de cobertura evidencia una base de pruebas funcional, pero con margen de mejora para alcanzar una mayor confianza y calidad en el software. Se recomienda establecer como meta un incremento progresivo de la cobertura, priorizando los m√≥dulos de mayor impacto en la operaci√≥n del sistema.